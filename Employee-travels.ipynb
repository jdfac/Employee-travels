{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis of Employee Travel Activities**\n",
    "\n",
    "\n",
    "**Overview**\n",
    "\n",
    "A company operating in the Northeastern United States has requested assistance in analyzing and visualizing some of their data related to the travel schedules and routes of their salespeople. The current state of the data requires that it be cleaned and filtered in order to be presented in ways which the company has requested. The following notebook demonstrates the steps taken to achieve this, while also allowing for modifications to be made to the filtering options to view different results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step in this process involves importing all of the necessary packages that will be required to complete this analysis. The packages are listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from osgeo import ogr\n",
    "from osgeo import osr\n",
    "import zipfile\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the necessary variables are set up at the top of the notebook, allowing users to swap out different datasets and alter filtering options. \n",
    "\n",
    "***Input Variables:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace = r\"C:\\Users\\joefa\\Documents\\GEOG489\\Lesson3\\Lesson3Assignment\\assignment3_data_March19\"\n",
    "employeeFile = \"employees.csv\"\n",
    "citiesFile = \"ne_cities.shp\"\n",
    "outputCSV = \"locationsByEmployee.csv\"\n",
    "outputSHP = \"travel_Line_jdf5716.shp\"\n",
    "employees = ['Jones, Frank', 'Brown, Justine', 'Samulson, Roger']\n",
    "startDate = datetime(2016, 6, 26)    # Start and end dates are entered as datetime objects.\n",
    "endDate = datetime(2017, 5, 11)      # To alter these objects, enter dates in the format (yyyy, mm, dd, (*optional hh, mm, ss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, the employee list is read into a Pandas DataFrame. This list features employee names, along with their work ID numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Smith, Richard</td>\n",
       "      <td>1234421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Moore, Lisa</td>\n",
       "      <td>1231233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jones, Frank</td>\n",
       "      <td>2132222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Brown, Justine</td>\n",
       "      <td>2132225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Samulson, Roger</td>\n",
       "      <td>3981232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Madison, Margaret</td>\n",
       "      <td>1876541</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Name       ID\n",
       "0     Smith, Richard  1234421\n",
       "1        Moore, Lisa  1231233\n",
       "2       Jones, Frank  2132222\n",
       "3     Brown, Justine  2132225\n",
       "4    Samulson, Roger  3981232\n",
       "5  Madison, Margaret  1876541"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "employee_df = pd.read_csv(os.path.join(workspace, employeeFile), header = None, names = ['Name', 'ID'])\n",
    "employee_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only want to pull data from relevant files. Since the workspace folder may contain other files with similar names, we set up a regular expression to filter through the folder and only create DataFrames from the correct files, which follow the format 'travel_####.csv'. These individual DataFrames are then concatenated into one single DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joefa\\anaconda3\\envs\\AC37\\lib\\site-packages\\ipykernel_launcher.py:9: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Start</th>\n",
       "      <th>End</th>\n",
       "      <th>Route</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2132222</td>\n",
       "      <td>2016-01-07 16:00:00</td>\n",
       "      <td>2016-01-26 12:00:00</td>\n",
       "      <td>Cleveland;Bangor;Erie;Philadelphia;New York;Al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1234421</td>\n",
       "      <td>2016-01-15 13:00:00</td>\n",
       "      <td>2016-01-31 17:00:00</td>\n",
       "      <td>Philadelphia;Portland;Harrisburg;Burlington;Er...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2132225</td>\n",
       "      <td>2016-01-29 12:00:00</td>\n",
       "      <td>2016-02-03 15:00:00</td>\n",
       "      <td>Bangor;Cleveland;Augusta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2132225</td>\n",
       "      <td>2016-02-10 07:00:00</td>\n",
       "      <td>2016-02-22 22:00:00</td>\n",
       "      <td>Altoona;Augusta;Altoona;Bangor;Augusta;Columbus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2132222</td>\n",
       "      <td>2016-02-19 14:00:00</td>\n",
       "      <td>2016-02-25 13:00:00</td>\n",
       "      <td>Boston;Philadelphia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID               Start                 End  \\\n",
       "0  2132222 2016-01-07 16:00:00 2016-01-26 12:00:00   \n",
       "0  1234421 2016-01-15 13:00:00 2016-01-31 17:00:00   \n",
       "0  2132225 2016-01-29 12:00:00 2016-02-03 15:00:00   \n",
       "0  2132225 2016-02-10 07:00:00 2016-02-22 22:00:00   \n",
       "0  2132222 2016-02-19 14:00:00 2016-02-25 13:00:00   \n",
       "\n",
       "                                               Route  \n",
       "0  Cleveland;Bangor;Erie;Philadelphia;New York;Al...  \n",
       "0  Philadelphia;Portland;Harrisburg;Burlington;Er...  \n",
       "0                           Bangor;Cleveland;Augusta  \n",
       "0    Altoona;Augusta;Altoona;Bangor;Augusta;Columbus  \n",
       "0                                Boston;Philadelphia  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This pattern will filter out any unwanted files (e.g., xyz_123.csv or travel_budgets.csv)\n",
    "pattern = 'travel_\\d\\d\\d\\d\\.csv$'\n",
    "\n",
    "# The pattern is pre-compiled to save time and resources as it will be tested on multiple files\n",
    "compiledRE = re.compile(pattern)\n",
    "\n",
    "# CSV files that match the pattern are selected and loaded as DataFrames.\n",
    "travelFiles = [pd.read_csv(os.path.join(workspace, file), sep = ',', header = None, names = ['ID', 'Start', 'End', 'Route'],\n",
    "                           parse_dates = [1, 2], date_parser= lambda x: pd.datetime.strptime(x, '%Y-%m-%d %H:%M:%S')) \n",
    "               for file in os.listdir(workspace) if re.match(compiledRE, file)]\n",
    "\n",
    "# The selected DataFrames are all added to one single DataFrame using the concat method.\n",
    "travelFiles_df = pd.concat(travelFiles)\n",
    "travelFiles_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to match the travel routes to the employees, we join the two DataFrames on the employee IDs. This makes it possible to identify who was on which trip without having to cross reference the separate DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>ID</th>\n",
       "      <th>Start</th>\n",
       "      <th>End</th>\n",
       "      <th>Route</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Smith, Richard</td>\n",
       "      <td>1234421</td>\n",
       "      <td>2016-01-15 13:00:00</td>\n",
       "      <td>2016-01-31 17:00:00</td>\n",
       "      <td>Philadelphia;Portland;Harrisburg;Burlington;Er...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Smith, Richard</td>\n",
       "      <td>1234421</td>\n",
       "      <td>2016-04-09 06:00:00</td>\n",
       "      <td>2016-04-16 22:00:00</td>\n",
       "      <td>Augusta;New York;Columbus;Syracuse;Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Smith, Richard</td>\n",
       "      <td>1234421</td>\n",
       "      <td>2016-04-22 15:00:00</td>\n",
       "      <td>2016-05-02 20:00:00</td>\n",
       "      <td>Columbus;Burlington;Augusta;Syracuse;Augusta;P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Smith, Richard</td>\n",
       "      <td>1234421</td>\n",
       "      <td>2016-05-09 06:00:00</td>\n",
       "      <td>2016-05-18 22:00:00</td>\n",
       "      <td>Boston;Albany;Harrisburg;Erie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Smith, Richard</td>\n",
       "      <td>1234421</td>\n",
       "      <td>2016-05-19 08:00:00</td>\n",
       "      <td>2016-05-25 16:00:00</td>\n",
       "      <td>Portland;Washington</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Madison, Margaret</td>\n",
       "      <td>1876541</td>\n",
       "      <td>2017-03-05 11:00:00</td>\n",
       "      <td>2017-03-17 14:00:00</td>\n",
       "      <td>Altoona;Columbus;Philadelphia;Augusta;Bangor;B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Madison, Margaret</td>\n",
       "      <td>1876541</td>\n",
       "      <td>2017-04-11 15:00:00</td>\n",
       "      <td>2017-04-25 18:00:00</td>\n",
       "      <td>Portland;Burlington;Cleveland;Altoona;Scranton...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Madison, Margaret</td>\n",
       "      <td>1876541</td>\n",
       "      <td>2017-05-20 15:00:00</td>\n",
       "      <td>2017-06-06 17:00:00</td>\n",
       "      <td>Albany;Boston;Pittsburgh;Cleveland;New York;Ph...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Madison, Margaret</td>\n",
       "      <td>1876541</td>\n",
       "      <td>2018-01-05 10:00:00</td>\n",
       "      <td>2018-01-16 13:00:00</td>\n",
       "      <td>Philadelphia;Burlington;Washington;Erie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Madison, Margaret</td>\n",
       "      <td>1876541</td>\n",
       "      <td>2017-12-03 08:00:00</td>\n",
       "      <td>2017-12-21 21:00:00</td>\n",
       "      <td>Bangor;New York;Burlington;Bangor;Erie;Portlan...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Name       ID               Start                 End  \\\n",
       "0      Smith, Richard  1234421 2016-01-15 13:00:00 2016-01-31 17:00:00   \n",
       "1      Smith, Richard  1234421 2016-04-09 06:00:00 2016-04-16 22:00:00   \n",
       "2      Smith, Richard  1234421 2016-04-22 15:00:00 2016-05-02 20:00:00   \n",
       "3      Smith, Richard  1234421 2016-05-09 06:00:00 2016-05-18 22:00:00   \n",
       "4      Smith, Richard  1234421 2016-05-19 08:00:00 2016-05-25 16:00:00   \n",
       "..                ...      ...                 ...                 ...   \n",
       "70  Madison, Margaret  1876541 2017-03-05 11:00:00 2017-03-17 14:00:00   \n",
       "71  Madison, Margaret  1876541 2017-04-11 15:00:00 2017-04-25 18:00:00   \n",
       "72  Madison, Margaret  1876541 2017-05-20 15:00:00 2017-06-06 17:00:00   \n",
       "73  Madison, Margaret  1876541 2018-01-05 10:00:00 2018-01-16 13:00:00   \n",
       "74  Madison, Margaret  1876541 2017-12-03 08:00:00 2017-12-21 21:00:00   \n",
       "\n",
       "                                                Route  \n",
       "0   Philadelphia;Portland;Harrisburg;Burlington;Er...  \n",
       "1           Augusta;New York;Columbus;Syracuse;Albany  \n",
       "2   Columbus;Burlington;Augusta;Syracuse;Augusta;P...  \n",
       "3                       Boston;Albany;Harrisburg;Erie  \n",
       "4                                 Portland;Washington  \n",
       "..                                                ...  \n",
       "70  Altoona;Columbus;Philadelphia;Augusta;Bangor;B...  \n",
       "71  Portland;Burlington;Cleveland;Altoona;Scranton...  \n",
       "72  Albany;Boston;Pittsburgh;Cleveland;New York;Ph...  \n",
       "73            Philadelphia;Burlington;Washington;Erie  \n",
       "74  Bangor;New York;Burlington;Bangor;Erie;Portlan...  \n",
       "\n",
       "[75 rows x 5 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the merge method is used to join two DataFrames based on a field.\n",
    "travelFiles_df_merged = employee_df.merge(travelFiles_df, left_on = 'ID', right_on = 'ID')\n",
    "travelFiles_df_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to create a copy of the DataFrame, perform our filtering operations on it (whose inputs were set up at the top of the workbook), orgranize the new DataFrame, and save it to a CSV file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>ID</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Start</th>\n",
       "      <th>End</th>\n",
       "      <th>Route</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Brown, Justine</td>\n",
       "      <td>2132225</td>\n",
       "      <td>5</td>\n",
       "      <td>2016-11-30 16:00:00</td>\n",
       "      <td>2016-12-06 14:00:00</td>\n",
       "      <td>Pittsburgh;Syracuse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Brown, Justine</td>\n",
       "      <td>2132225</td>\n",
       "      <td>9</td>\n",
       "      <td>2016-12-12 12:00:00</td>\n",
       "      <td>2016-12-21 19:00:00</td>\n",
       "      <td>Columbus;Boston;Pittsburgh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Brown, Justine</td>\n",
       "      <td>2132225</td>\n",
       "      <td>12</td>\n",
       "      <td>2016-08-02 13:00:00</td>\n",
       "      <td>2016-08-14 16:00:00</td>\n",
       "      <td>Albany;Scranton;Philadelphia;Scranton;Augusta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Brown, Justine</td>\n",
       "      <td>2132225</td>\n",
       "      <td>12</td>\n",
       "      <td>2017-01-07 11:00:00</td>\n",
       "      <td>2017-01-19 17:00:00</td>\n",
       "      <td>Harrisburg;Portland;Boston;Syracuse;Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Brown, Justine</td>\n",
       "      <td>2132225</td>\n",
       "      <td>17</td>\n",
       "      <td>2017-03-27 06:00:00</td>\n",
       "      <td>2017-04-13 14:00:00</td>\n",
       "      <td>Portland;Boston;Bangor;Washington;Harrisburg;P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Brown, Justine</td>\n",
       "      <td>2132225</td>\n",
       "      <td>19</td>\n",
       "      <td>2016-11-04 17:00:00</td>\n",
       "      <td>2016-11-23 20:00:00</td>\n",
       "      <td>New York;Portland;Boston;Portland;Washington;P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Jones, Frank</td>\n",
       "      <td>2132222</td>\n",
       "      <td>5</td>\n",
       "      <td>2016-07-10 18:00:00</td>\n",
       "      <td>2016-07-15 18:00:00</td>\n",
       "      <td>Harrisburg;Augusta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Jones, Frank</td>\n",
       "      <td>2132222</td>\n",
       "      <td>10</td>\n",
       "      <td>2017-01-18 12:00:00</td>\n",
       "      <td>2017-01-28 19:00:00</td>\n",
       "      <td>Philadelphia;Boston;Altoona;Harrisburg;Scranton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Jones, Frank</td>\n",
       "      <td>2132222</td>\n",
       "      <td>17</td>\n",
       "      <td>2017-03-16 17:00:00</td>\n",
       "      <td>2017-04-02 18:00:00</td>\n",
       "      <td>Augusta;New York;Scranton;Columbus;Washington;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Samulson, Roger</td>\n",
       "      <td>3981232</td>\n",
       "      <td>7</td>\n",
       "      <td>2016-10-15 07:00:00</td>\n",
       "      <td>2016-10-22 17:00:00</td>\n",
       "      <td>Boston;Syracuse;Portland;Altoona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Samulson, Roger</td>\n",
       "      <td>3981232</td>\n",
       "      <td>7</td>\n",
       "      <td>2017-02-10 07:00:00</td>\n",
       "      <td>2017-02-17 19:00:00</td>\n",
       "      <td>Portland;Augusta;Burlington;Philadelphia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Samulson, Roger</td>\n",
       "      <td>3981232</td>\n",
       "      <td>9</td>\n",
       "      <td>2016-07-24 17:00:00</td>\n",
       "      <td>2016-08-03 12:00:00</td>\n",
       "      <td>Erie;Syracuse;Philadelphia;Bangor;Scranton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Samulson, Roger</td>\n",
       "      <td>3981232</td>\n",
       "      <td>15</td>\n",
       "      <td>2017-02-24 06:00:00</td>\n",
       "      <td>2017-03-11 20:00:00</td>\n",
       "      <td>New York;Augusta;Pittsburgh;Cleveland;Altoona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Samulson, Roger</td>\n",
       "      <td>3981232</td>\n",
       "      <td>18</td>\n",
       "      <td>2016-12-25 17:00:00</td>\n",
       "      <td>2017-01-12 17:00:00</td>\n",
       "      <td>Boston;Cleveland;Pittsburgh;Philadelphia;Harri...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Name       ID  Duration               Start  \\\n",
       "0    Brown, Justine  2132225         5 2016-11-30 16:00:00   \n",
       "1    Brown, Justine  2132225         9 2016-12-12 12:00:00   \n",
       "2    Brown, Justine  2132225        12 2016-08-02 13:00:00   \n",
       "3    Brown, Justine  2132225        12 2017-01-07 11:00:00   \n",
       "4    Brown, Justine  2132225        17 2017-03-27 06:00:00   \n",
       "5    Brown, Justine  2132225        19 2016-11-04 17:00:00   \n",
       "6      Jones, Frank  2132222         5 2016-07-10 18:00:00   \n",
       "7      Jones, Frank  2132222        10 2017-01-18 12:00:00   \n",
       "8      Jones, Frank  2132222        17 2017-03-16 17:00:00   \n",
       "9   Samulson, Roger  3981232         7 2016-10-15 07:00:00   \n",
       "10  Samulson, Roger  3981232         7 2017-02-10 07:00:00   \n",
       "11  Samulson, Roger  3981232         9 2016-07-24 17:00:00   \n",
       "12  Samulson, Roger  3981232        15 2017-02-24 06:00:00   \n",
       "13  Samulson, Roger  3981232        18 2016-12-25 17:00:00   \n",
       "\n",
       "                   End                                              Route  \n",
       "0  2016-12-06 14:00:00                                Pittsburgh;Syracuse  \n",
       "1  2016-12-21 19:00:00                         Columbus;Boston;Pittsburgh  \n",
       "2  2016-08-14 16:00:00      Albany;Scranton;Philadelphia;Scranton;Augusta  \n",
       "3  2017-01-19 17:00:00         Harrisburg;Portland;Boston;Syracuse;Albany  \n",
       "4  2017-04-13 14:00:00  Portland;Boston;Bangor;Washington;Harrisburg;P...  \n",
       "5  2016-11-23 20:00:00  New York;Portland;Boston;Portland;Washington;P...  \n",
       "6  2016-07-15 18:00:00                                 Harrisburg;Augusta  \n",
       "7  2017-01-28 19:00:00    Philadelphia;Boston;Altoona;Harrisburg;Scranton  \n",
       "8  2017-04-02 18:00:00  Augusta;New York;Scranton;Columbus;Washington;...  \n",
       "9  2016-10-22 17:00:00                   Boston;Syracuse;Portland;Altoona  \n",
       "10 2017-02-17 19:00:00           Portland;Augusta;Burlington;Philadelphia  \n",
       "11 2016-08-03 12:00:00         Erie;Syracuse;Philadelphia;Bangor;Scranton  \n",
       "12 2017-03-11 20:00:00      New York;Augusta;Pittsburgh;Cleveland;Altoona  \n",
       "13 2017-01-12 17:00:00  Boston;Cleveland;Pittsburgh;Philadelphia;Harri...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only rows that meet the supplied filters will be added to the new DataFrame, which was copied from\n",
    "# the original to avoid any disturbances to the file. \n",
    "filteredTravelFiles_df = travelFiles_df_merged[(travelFiles_df_merged.Start >= startDate) & \n",
    "                                              (travelFiles_df_merged.End <= endDate) & \n",
    "                                              (travelFiles_df_merged.Name.isin(employees))].copy()\n",
    "\n",
    "\n",
    "# A new field, 'Duration', is added to the new DataFrame. This field is calculated by subtracting\n",
    "# the end date from the start date, using the datetime module. The columns are then reorganized\n",
    "# and finally the DataFrame is exported to a CSV file, using the to_csv() function. \n",
    "filteredTravelFiles_df['Duration'] = ((filteredTravelFiles_df.End - filteredTravelFiles_df.Start).dt.days)\n",
    "filteredTravelFiles_df = filteredTravelFiles_df[['Name', 'ID', 'Duration', 'Start', 'End', 'Route']].sort_values(['Name', 'Duration', 'Start', 'End']).reset_index(drop = True)\n",
    "filteredTravelFiles_df.to_csv(os.path.join(workspace, outputCSV))\n",
    "filteredTravelFiles_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Creating a shapefile**\n",
    "\n",
    "While the company wanted to have their data organized in tabular form, they also requested to be able visualize these trips on a map. For this step, we upload a city point shapefile using geopandas to match the cities' coordinates with the trip DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OBJECTID</th>\n",
       "      <th>UIDENT</th>\n",
       "      <th>POPCLASS</th>\n",
       "      <th>NAME</th>\n",
       "      <th>CAPITAL</th>\n",
       "      <th>STATEABB</th>\n",
       "      <th>COUNTRY</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>62507.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Bangor</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>US-ME</td>\n",
       "      <td>USA</td>\n",
       "      <td>POINT (-68.77619 44.81189)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>64707.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Waterville</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>US-ME</td>\n",
       "      <td>USA</td>\n",
       "      <td>POINT (-69.62073 44.53724)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23</td>\n",
       "      <td>65607.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Augusta</td>\n",
       "      <td>1.0</td>\n",
       "      <td>US-ME</td>\n",
       "      <td>USA</td>\n",
       "      <td>POINT (-69.78141 44.32166)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26</td>\n",
       "      <td>66707.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>US-NH</td>\n",
       "      <td>USA</td>\n",
       "      <td>POINT (-71.19324 44.46470)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29</td>\n",
       "      <td>67407.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Lewiston</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>US-ME</td>\n",
       "      <td>USA</td>\n",
       "      <td>POINT (-70.19406 44.10972)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>406</td>\n",
       "      <td>121107.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Hickory</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>US-NC</td>\n",
       "      <td>USA</td>\n",
       "      <td>POINT (-81.36642 35.72144)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>413</td>\n",
       "      <td>121907.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Knoxville</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>US-TN</td>\n",
       "      <td>USA</td>\n",
       "      <td>POINT (-83.93407 35.98019)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>414</td>\n",
       "      <td>122007.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Oak Ridge</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>US-TN</td>\n",
       "      <td>USA</td>\n",
       "      <td>POINT (-84.25911 36.00918)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>421</td>\n",
       "      <td>122707.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Asheville</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>US-NC</td>\n",
       "      <td>USA</td>\n",
       "      <td>POINT (-82.54221 35.60217)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>682</td>\n",
       "      <td>100407.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Washington</td>\n",
       "      <td>2.0</td>\n",
       "      <td>US-MD</td>\n",
       "      <td>USA</td>\n",
       "      <td>POINT (-76.97077 38.95144)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>137 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    OBJECTID    UIDENT  POPCLASS        NAME  CAPITAL STATEABB COUNTRY  \\\n",
       "0         15   62507.0       2.0      Bangor     -1.0    US-ME     USA   \n",
       "1         20   64707.0       2.0  Waterville     -1.0    US-ME     USA   \n",
       "2         23   65607.0       2.0     Augusta      1.0    US-ME     USA   \n",
       "3         26   66707.0       2.0      Berlin     -1.0    US-NH     USA   \n",
       "4         29   67407.0       2.0    Lewiston     -1.0    US-ME     USA   \n",
       "..       ...       ...       ...         ...      ...      ...     ...   \n",
       "132      406  121107.0       2.0     Hickory     -1.0    US-NC     USA   \n",
       "133      413  121907.0       3.0   Knoxville     -1.0    US-TN     USA   \n",
       "134      414  122007.0       2.0   Oak Ridge     -1.0    US-TN     USA   \n",
       "135      421  122707.0       2.0   Asheville     -1.0    US-NC     USA   \n",
       "136      682  100407.0       3.0  Washington      2.0    US-MD     USA   \n",
       "\n",
       "                       geometry  \n",
       "0    POINT (-68.77619 44.81189)  \n",
       "1    POINT (-69.62073 44.53724)  \n",
       "2    POINT (-69.78141 44.32166)  \n",
       "3    POINT (-71.19324 44.46470)  \n",
       "4    POINT (-70.19406 44.10972)  \n",
       "..                          ...  \n",
       "132  POINT (-81.36642 35.72144)  \n",
       "133  POINT (-83.93407 35.98019)  \n",
       "134  POINT (-84.25911 36.00918)  \n",
       "135  POINT (-82.54221 35.60217)  \n",
       "136  POINT (-76.97077 38.95144)  \n",
       "\n",
       "[137 rows x 8 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The geopandas function read_file() is used to read the city point shapefile to a DataFrame.\n",
    "cityData = gpd.read_file(os.path.join(workspace, citiesFile))\n",
    "cityData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coordinates are extracted from the city DataFrame and added to tuples which align with the various routes. These tuples are joined to the main DataFrame to allow a line shapefile to be created. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>ID</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Start</th>\n",
       "      <th>End</th>\n",
       "      <th>Route</th>\n",
       "      <th>linestring</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Brown, Justine</td>\n",
       "      <td>2132225</td>\n",
       "      <td>5</td>\n",
       "      <td>2016-11-30 16:00:00</td>\n",
       "      <td>2016-12-06 14:00:00</td>\n",
       "      <td>Pittsburgh;Syracuse</td>\n",
       "      <td>LineString (-79.91439598338775 40.447399277754...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Brown, Justine</td>\n",
       "      <td>2132225</td>\n",
       "      <td>9</td>\n",
       "      <td>2016-12-12 12:00:00</td>\n",
       "      <td>2016-12-21 19:00:00</td>\n",
       "      <td>Columbus;Boston;Pittsburgh</td>\n",
       "      <td>LineString (-82.98182532058195 39.972384950705...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Brown, Justine</td>\n",
       "      <td>2132225</td>\n",
       "      <td>12</td>\n",
       "      <td>2016-08-02 13:00:00</td>\n",
       "      <td>2016-08-14 16:00:00</td>\n",
       "      <td>Albany;Scranton;Philadelphia;Scranton;Augusta</td>\n",
       "      <td>LineString (-73.78191599152962 42.674015577157...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Brown, Justine</td>\n",
       "      <td>2132225</td>\n",
       "      <td>12</td>\n",
       "      <td>2017-01-07 11:00:00</td>\n",
       "      <td>2017-01-19 17:00:00</td>\n",
       "      <td>Harrisburg;Portland;Boston;Syracuse;Albany</td>\n",
       "      <td>LineString (-76.82629734234831 40.266819768117...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Brown, Justine</td>\n",
       "      <td>2132225</td>\n",
       "      <td>17</td>\n",
       "      <td>2017-03-27 06:00:00</td>\n",
       "      <td>2017-04-13 14:00:00</td>\n",
       "      <td>Portland;Boston;Bangor;Washington;Harrisburg;P...</td>\n",
       "      <td>LineString (-70.27758484016806 43.698554552950...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Brown, Justine</td>\n",
       "      <td>2132225</td>\n",
       "      <td>19</td>\n",
       "      <td>2016-11-04 17:00:00</td>\n",
       "      <td>2016-11-23 20:00:00</td>\n",
       "      <td>New York;Portland;Boston;Portland;Washington;P...</td>\n",
       "      <td>LineString (-73.95605368612854 40.648657910034...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Jones, Frank</td>\n",
       "      <td>2132222</td>\n",
       "      <td>5</td>\n",
       "      <td>2016-07-10 18:00:00</td>\n",
       "      <td>2016-07-15 18:00:00</td>\n",
       "      <td>Harrisburg;Augusta</td>\n",
       "      <td>LineString (-76.82629734234831 40.266819768117...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Jones, Frank</td>\n",
       "      <td>2132222</td>\n",
       "      <td>10</td>\n",
       "      <td>2017-01-18 12:00:00</td>\n",
       "      <td>2017-01-28 19:00:00</td>\n",
       "      <td>Philadelphia;Boston;Altoona;Harrisburg;Scranton</td>\n",
       "      <td>LineString (-75.16727846213115 39.941228213611...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Jones, Frank</td>\n",
       "      <td>2132222</td>\n",
       "      <td>17</td>\n",
       "      <td>2017-03-16 17:00:00</td>\n",
       "      <td>2017-04-02 18:00:00</td>\n",
       "      <td>Augusta;New York;Scranton;Columbus;Washington;...</td>\n",
       "      <td>LineString (-69.78141264717578 44.321655641294...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Samulson, Roger</td>\n",
       "      <td>3981232</td>\n",
       "      <td>7</td>\n",
       "      <td>2016-10-15 07:00:00</td>\n",
       "      <td>2016-10-22 17:00:00</td>\n",
       "      <td>Boston;Syracuse;Portland;Altoona</td>\n",
       "      <td>LineString (-71.08008355451227 42.362833160122...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Samulson, Roger</td>\n",
       "      <td>3981232</td>\n",
       "      <td>7</td>\n",
       "      <td>2017-02-10 07:00:00</td>\n",
       "      <td>2017-02-17 19:00:00</td>\n",
       "      <td>Portland;Augusta;Burlington;Philadelphia</td>\n",
       "      <td>LineString (-70.27758484016806 43.698554552950...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Samulson, Roger</td>\n",
       "      <td>3981232</td>\n",
       "      <td>9</td>\n",
       "      <td>2016-07-24 17:00:00</td>\n",
       "      <td>2016-08-03 12:00:00</td>\n",
       "      <td>Erie;Syracuse;Philadelphia;Bangor;Scranton</td>\n",
       "      <td>LineString (-80.06309969219689 42.104663488929...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Samulson, Roger</td>\n",
       "      <td>3981232</td>\n",
       "      <td>15</td>\n",
       "      <td>2017-02-24 06:00:00</td>\n",
       "      <td>2017-03-11 20:00:00</td>\n",
       "      <td>New York;Augusta;Pittsburgh;Cleveland;Altoona</td>\n",
       "      <td>LineString (-73.95605368612854 40.648657910034...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Samulson, Roger</td>\n",
       "      <td>3981232</td>\n",
       "      <td>18</td>\n",
       "      <td>2016-12-25 17:00:00</td>\n",
       "      <td>2017-01-12 17:00:00</td>\n",
       "      <td>Boston;Cleveland;Pittsburgh;Philadelphia;Harri...</td>\n",
       "      <td>LineString (-71.08008355451227 42.362833160122...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Name       ID  Duration               Start  \\\n",
       "0    Brown, Justine  2132225         5 2016-11-30 16:00:00   \n",
       "1    Brown, Justine  2132225         9 2016-12-12 12:00:00   \n",
       "2    Brown, Justine  2132225        12 2016-08-02 13:00:00   \n",
       "3    Brown, Justine  2132225        12 2017-01-07 11:00:00   \n",
       "4    Brown, Justine  2132225        17 2017-03-27 06:00:00   \n",
       "5    Brown, Justine  2132225        19 2016-11-04 17:00:00   \n",
       "6      Jones, Frank  2132222         5 2016-07-10 18:00:00   \n",
       "7      Jones, Frank  2132222        10 2017-01-18 12:00:00   \n",
       "8      Jones, Frank  2132222        17 2017-03-16 17:00:00   \n",
       "9   Samulson, Roger  3981232         7 2016-10-15 07:00:00   \n",
       "10  Samulson, Roger  3981232         7 2017-02-10 07:00:00   \n",
       "11  Samulson, Roger  3981232         9 2016-07-24 17:00:00   \n",
       "12  Samulson, Roger  3981232        15 2017-02-24 06:00:00   \n",
       "13  Samulson, Roger  3981232        18 2016-12-25 17:00:00   \n",
       "\n",
       "                   End                                              Route  \\\n",
       "0  2016-12-06 14:00:00                                Pittsburgh;Syracuse   \n",
       "1  2016-12-21 19:00:00                         Columbus;Boston;Pittsburgh   \n",
       "2  2016-08-14 16:00:00      Albany;Scranton;Philadelphia;Scranton;Augusta   \n",
       "3  2017-01-19 17:00:00         Harrisburg;Portland;Boston;Syracuse;Albany   \n",
       "4  2017-04-13 14:00:00  Portland;Boston;Bangor;Washington;Harrisburg;P...   \n",
       "5  2016-11-23 20:00:00  New York;Portland;Boston;Portland;Washington;P...   \n",
       "6  2016-07-15 18:00:00                                 Harrisburg;Augusta   \n",
       "7  2017-01-28 19:00:00    Philadelphia;Boston;Altoona;Harrisburg;Scranton   \n",
       "8  2017-04-02 18:00:00  Augusta;New York;Scranton;Columbus;Washington;...   \n",
       "9  2016-10-22 17:00:00                   Boston;Syracuse;Portland;Altoona   \n",
       "10 2017-02-17 19:00:00           Portland;Augusta;Burlington;Philadelphia   \n",
       "11 2016-08-03 12:00:00         Erie;Syracuse;Philadelphia;Bangor;Scranton   \n",
       "12 2017-03-11 20:00:00      New York;Augusta;Pittsburgh;Cleveland;Altoona   \n",
       "13 2017-01-12 17:00:00  Boston;Cleveland;Pittsburgh;Philadelphia;Harri...   \n",
       "\n",
       "                                           linestring  \n",
       "0   LineString (-79.91439598338775 40.447399277754...  \n",
       "1   LineString (-82.98182532058195 39.972384950705...  \n",
       "2   LineString (-73.78191599152962 42.674015577157...  \n",
       "3   LineString (-76.82629734234831 40.266819768117...  \n",
       "4   LineString (-70.27758484016806 43.698554552950...  \n",
       "5   LineString (-73.95605368612854 40.648657910034...  \n",
       "6   LineString (-76.82629734234831 40.266819768117...  \n",
       "7   LineString (-75.16727846213115 39.941228213611...  \n",
       "8   LineString (-69.78141264717578 44.321655641294...  \n",
       "9   LineString (-71.08008355451227 42.362833160122...  \n",
       "10  LineString (-70.27758484016806 43.698554552950...  \n",
       "11  LineString (-80.06309969219689 42.104663488929...  \n",
       "12  LineString (-73.95605368612854 40.648657910034...  \n",
       "13  LineString (-71.08008355451227 42.362833160122...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A list comprehension is used to parse through the route strings and search for each city's accompanying \n",
    "# coordinates. This is then converted to a DataFrame and joined to the main DataFrame. \n",
    "wkt = [ 'LineString (' + ','.join([ '{0} {1}'.\\\n",
    "    format(cityData[cityData.NAME == city].geometry.x.iloc[0],\\\n",
    "           cityData[cityData.NAME == city].geometry.y.iloc[0]) \\\n",
    "           for city in r.split(';') ])+')' for r in filteredTravelFiles_df.Route]\n",
    "\n",
    "wkt_df = pd.DataFrame(wkt, columns = ['linestring'])\n",
    "\n",
    "travelFilesLinestring_df = filteredTravelFiles_df.join(wkt_df)\n",
    "travelFilesLinestring_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, a new shapefile is created and saved under a variable name set at the top of the notebook. Attributes of the shapefile include the employee's name, the route, and the duration of the trip. This information is matched with a line that traces the trip through its various stops. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr = osr.SpatialReference()   # create spatial reference object\n",
    "sr.ImportFromEPSG(4326)       # set it to EPSG:4326\n",
    "drv = ogr.GetDriverByName('ESRI Shapefile')\n",
    "outfile = drv.CreateDataSource(os.path.join(workspace, outputSHP)) \n",
    "outlayer = outfile.CreateLayer(outputSHP.replace('.shp', ''), geom_type=ogr.wkbLineString, srs = sr)  # create new layer in the shapefile \n",
    " \n",
    "nameField = ogr.FieldDefn('Name', ogr.OFTString)        # create new field of type string called Name to store the employee names\n",
    "outlayer.CreateField(nameField)                         # add this new field to the output layer\n",
    "nameField = ogr.FieldDefn('Route', ogr.OFTString)       # create new field of type string called Route to store the route strings\n",
    "outlayer.CreateField(nameField)                         # add this new field to the output layer\n",
    "nameField = ogr.FieldDefn('Duration', ogr.OFTInteger)   # create new field of type integer called Duration to store the duration numbers\n",
    "outlayer.CreateField(nameField)                         # add this new field to the output layer\n",
    "\n",
    "# add this new field to the output layer\n",
    " \n",
    "featureDefn = outlayer.GetLayerDefn()\n",
    "\n",
    "\n",
    "for row in travelFilesLinestring_df.itertuples():        # loop through DataFrame with the itertuples method\n",
    "    ingeom = row.linestring                              # get geometry of feature from the linstring tuple\n",
    "    outgeom = ogr.CreateGeometryFromWkt(ingeom)          # Create geometry from wkt using the linstring tuples\n",
    " \n",
    "    outFeature = ogr.Feature(featureDefn)                # create a new feature\n",
    "    outFeature.SetGeometry(outgeom)                      # set its geometry to outgeom\n",
    "    outFeature.SetField('Name', row.Name)                # set the feature's Name field to the Name value of the DataFrame\n",
    "    outFeature.SetField('Route', row.Route)              # set the feature's Route field to the Route value of the DataFrame\n",
    "    outFeature.SetField('Duration', row.Duration)        # set the feature's Duration field to the Duration value of the DataFrame \n",
    "    outlayer.CreateFeature(outFeature)                   # finally add the new output feature to outlayer\n",
    "    outFeature = None\n",
    " \n",
    "outfile = None         # close output file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to visualize these travel routes, we will zip the shapefile and upload it to ArcGIS Online using the Esri API. This will be viewable through the map widget blow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create zipped shapefile for a given filename without extension\n",
    "def zipShapefile(name):\n",
    "    compiledRE = re.compile(name+'(?!.zip)\\....$')\n",
    "    with zipfile.ZipFile( os.path.join(workspace, name + '.zip'), 'w', zipfile.ZIP_DEFLATED) as zf:  # create zipfile\n",
    "        for file in os.listdir(workspace):                                                           # go through files in workspace\n",
    "            if compiledRE.match(file):                                                               # test whether file is part of the shapefile to be zipped\n",
    "                zf.write(os.path.join(workspace,file),file,zipfile.ZIP_DEFLATED)                     # add file to zipfile\n",
    "                \n",
    "# create zipped version of observation shapefile\n",
    "zipShapefile( os.path.splitext(outputSHP)[0] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code connects this notebook to ArcGIS. Adjustments may need to be made to the filepaths, depending on where ArcGIS is stored on your local machine. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "os.environ[\"PATH\"] = r\"{};{}\".format(os.environ[\"PATH\"], r\"C:\\Program Files\\ArcGIS\\Pro\\bin\")\n",
    "sys.path.append(r\"C:\\Program Files\\ArcGIS\\Pro\\Resources\\ArcPy\")\n",
    "import arcgis\n",
    "from arcgis.gis import GIS\n",
    "gis = GIS('pro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shapefile is published on ArcGIS Online and ready for viewing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the shapefile to ArcGIS Online\n",
    "travelRoutes = gis.content.add({'type': 'Shapefile'}, os.path.join(workspace, outputSHP.replace('.shp','.zip')))\n",
    "\n",
    "# Publish the layer in ArcGIS Online \n",
    "travelRoutesFS = travelRoutes.publish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f08695540364184bf249782792b784a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MapView(layout=Layout(height='400px', width='100%'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"map-static-img-preview-d4371354-b3c6-4ac8-a3d3-928768c091af\"><img src=\"\"></img></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"map-html-embed-preview-d4371354-b3c6-4ac8-a3d3-928768c091af\"></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set up the map\n",
    "travelMap = gis.map()\n",
    "\n",
    "# Add the published layer to the map\n",
    "travelMap.add_layer(travelRoutesFS, {})\n",
    "\n",
    "# View the map with the layer\n",
    "travelMap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "This notebook takes travel data from a company operating in the Northeastern United States. Their original datasets were scattered throughout their organization and did not contain all of the necessary information to perform efficient analysis and make important business decisions. This notebook transformed the data to make it more accessible, filterable, and presentable. Users can adjust data sources and filtering option at the top of the workbook (in the *input variables* section) to perform similar tasks and answer any further questions they may have about the data and the travelling activity at their company. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
